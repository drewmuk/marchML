# marchML

This is my code that I submitted to Kaggle's **[March Machine Learning Mania 2025](www.kaggle.com/competitions/march-machine-learning-mania-2025)**, a competition to create the most accurate probablistic predictions for the 2025 editions of the NCAA Division I basketball tournaments (men's and women's). Data in the form of game-by-game box scores from this season and seasons back to 1985, previous years' tournament results back to 2003 (men's) and 2010 (women's), and more were provided. The goal was to minimize Brier score loss (mean squared error between predicted probability and game outcome) for the 134 games across the two tournaments this year. As of March 28 (through 100 games) my model is in the 70th percentile among all entrants to this competition, with an average Brier score of 0.12166.

The format required submitting predictions for who would win given every possible combination of teams in the tournament. For both the men's and women's tournaments, my predictions used a weighted average of a random forest model, an XGBoost model, and a pre-tournament sportsbook betting odds ratio. I used grid search cross-validation to select parameters for the former two models for each gender (separately), and trained/tested them based on the seasons where tournament results were available. The end result was a CSV file which displayed two team IDs and the probability of the team with the first ID winning the game.

My model used various statistics as factors in win probability, scaled to a N(0,1) distribution including: each team's points for and against per game, four factors (effective field goal %, turnover %, free throw rate, and offensive rebound %) for and against, blocks per game, and aggregate [Massey rankings](https://masseyratings.com/cb/ncaa-d1/ratings). I also added standardized variables for each team's *conference's* statistics. So for example, for Duke in 2023-24, the model would include both the number of standard deviations above or below the DI average of points that Duke scored per game that season, and also the number the ACC as a whole scored per game that year compared to other conferences. I found interesting trends, especially that difference conferences have widely ranging free throw rates and FT% has been increasing over time, such that I believe this is a worthwile addition. 

After finishing the feature engineering, I fit two types of machine learning models: a Random Forest classifier and an eXtreme Gradient Boosting classifier. I used a grid search cross-validation for each model to find the best parameters in several fields, including the number of estimators, maximum depth, and learning rate, among others. With these models I made predictions for the 2025 data, which were not including at any stage of the training process. The final CSV file contains a probability (0 to 1) for each possible game of the first team listed winning the game.
